{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "import scipy.optimize\n",
    "import symbol_data\n",
    "import portfolio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_df = pd.read_csv(Path('./Resources/SPX.csv'), \n",
    "                    index_col='Date', \n",
    "                    parse_dates=True,\n",
    "                    infer_datetime_format=True\n",
    "                    )\n",
    "spx_daily_returns = spx_df['Close'].pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = ['AAPL', 'ACN', 'ADBE', 'ADI', 'ADSK', 'AKAM', 'AMAT', 'AMD', 'CRM', 'DELL', 'DOCU', 'EPAM', 'FIS', 'FISV', 'IBM', 'INFY', 'LRCX', 'MSFT', 'MU', 'NOW', 'NVDA', 'ORCL', 'SAP', 'TEAM', 'TXN', 'WDAY', 'WORK', 'XLNX', 'ZBRA', 'ZEN', 'ZI', 'ZS']\n",
    "# This function may have to be rewritten to accomodate Anurag's data functions\n",
    "# as it performs all the analysis within the same loop as retrieving the data.\n",
    "def stock_data_calculator(stocks):\n",
    "    # Create an empty dictionary to store the stock data\n",
    "    stock_data_dict = {}\n",
    "    # This section can be replaced by Anurag's function\n",
    "    for stock in stocks:\n",
    "        # stock_df = pd.read_csv(\n",
    "        #     Path(f'./Resources/{stock}.csv'), \n",
    "        #     index_col = 'Date', \n",
    "        #     parse_dates = True, \n",
    "        #     infer_datetime_format=True\n",
    "        #     )\n",
    "        stock_df = portfolio_data.get_portfolio_historical_data(stock)\n",
    "        daily_returns = stock_df['Close'].pct_change().dropna()\n",
    "        daily_returns_df = pd.concat(\n",
    "            [daily_returns, spx_daily_returns], \n",
    "            axis=1,\n",
    "            join='inner', \n",
    "            keys = [stock, 'SPX']\n",
    "            )\n",
    "        covariance = daily_returns_df[stock].cov(daily_returns_df['SPX'])\n",
    "        beta = covariance / daily_returns_df['SPX'].var()\n",
    "\n",
    "        std = daily_returns.std()\n",
    "\n",
    "        var = daily_returns.var()\n",
    "\n",
    "        expected_return = .035 + beta*(.1-.035)\n",
    "        \n",
    "        stock_data_dict[stock] = {'expected_return': expected_return, 'std': std, 'var': var, 'beta': beta}\n",
    "    return stock_data_dict\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': {'expected_return': 0.1021857914988607,\n",
       "  'std': 0.02079129793240788,\n",
       "  'var': 0.0004322780697141482,\n",
       "  'beta': 1.0336275615209338},\n",
       " 'ACN': {'expected_return': 0.0928258962563413,\n",
       "  'std': 0.01645928931954835,\n",
       "  'var': 0.0002709082049045985,\n",
       "  'beta': 0.8896291731744815},\n",
       " 'ADBE': {'expected_return': 0.11004981725358733,\n",
       "  'std': 0.021328535684571374,\n",
       "  'var': 0.00045490643444803455,\n",
       "  'beta': 1.1546125731321126},\n",
       " 'ADI': {'expected_return': 0.10267257755225005,\n",
       "  'std': 0.01951063375075435,\n",
       "  'var': 0.0003806648293560747,\n",
       "  'beta': 1.0411165777269238},\n",
       " 'ADSK': {'expected_return': 0.11739155821007816,\n",
       "  'std': 0.024441902649579843,\n",
       "  'var': 0.0005974066051315382,\n",
       "  'beta': 1.2675624340012024},\n",
       " 'AKAM': {'expected_return': 0.1100147458956259,\n",
       "  'std': 0.027881047884079174,\n",
       "  'var': 0.0007773528311143157,\n",
       "  'beta': 1.15407301377886},\n",
       " 'AMAT': {'expected_return': 0.11417312976324465,\n",
       "  'std': 0.022677234403613647,\n",
       "  'var': 0.0005142569601964385,\n",
       "  'beta': 1.2180481502037637},\n",
       " 'AMD': {'expected_return': 0.12732094055162752,\n",
       "  'std': 0.03782338612042469,\n",
       "  'var': 0.0014306085376147354,\n",
       "  'beta': 1.420322162332731},\n",
       " 'CRM': {'expected_return': 0.11620242445771302,\n",
       "  'std': 0.02639358130033962,\n",
       "  'var': 0.0006966211338576372,\n",
       "  'beta': 1.2492680685802002},\n",
       " 'DELL': {'expected_return': 0.10415814356314858,\n",
       "  'std': 0.023051406514854465,\n",
       "  'var': 0.0005313673423130748,\n",
       "  'beta': 1.063971439433055},\n",
       " 'DOCU': {'expected_return': 0.089261053257897,\n",
       "  'std': 0.03365813836702715,\n",
       "  'var': 0.001132870278333945,\n",
       "  'beta': 0.8347854347368768},\n",
       " 'EPAM': {'expected_return': 0.11647851278192085,\n",
       "  'std': 0.023734320294813187,\n",
       "  'var': 0.0005633179598567811,\n",
       "  'beta': 1.2535155812603207},\n",
       " 'FIS': {'expected_return': 0.0984660090379284,\n",
       "  'std': 0.01934357222302197,\n",
       "  'var': 0.00037417378634726703,\n",
       "  'beta': 0.9764001390450523},\n",
       " 'FISV': {'expected_return': 0.09759670013648675,\n",
       "  'std': 0.01621841222833527,\n",
       "  'var': 0.00026303689520821503,\n",
       "  'beta': 0.9630261559459499},\n",
       " 'IBM': {'expected_return': 0.08852499046910653,\n",
       "  'std': 0.01477298536660975,\n",
       "  'var': 0.0002182410966420658,\n",
       "  'beta': 0.8234613918324081},\n",
       " 'INFY': {'expected_return': 0.10501100969943386,\n",
       "  'std': 0.021950736472259064,\n",
       "  'var': 0.0004818348316745642,\n",
       "  'beta': 1.077092456914367},\n",
       " 'LRCX': {'expected_return': 0.12035219943898628,\n",
       "  'std': 0.025306559487743175,\n",
       "  'var': 0.000640421953106684,\n",
       "  'beta': 1.313110760599789},\n",
       " 'MSFT': {'expected_return': 0.10116822291240551,\n",
       "  'std': 0.017718607130737325,\n",
       "  'var': 0.0003139490386534156,\n",
       "  'beta': 1.017972660190854},\n",
       " 'MU': {'expected_return': 0.13664155748761034,\n",
       "  'std': 0.033749637648477326,\n",
       "  'var': 0.001139038041403518,\n",
       "  'beta': 1.563716269040159},\n",
       " 'NOW': {'expected_return': 0.11841874942585381,\n",
       "  'std': 0.025740785624156493,\n",
       "  'var': 0.0006625880445487816,\n",
       "  'beta': 1.2833653757823662},\n",
       " 'NVDA': {'expected_return': 0.12820947636431657,\n",
       "  'std': 0.03041527606501578,\n",
       "  'var': 0.0009250890181111218,\n",
       "  'beta': 1.4339919440664086},\n",
       " 'ORCL': {'expected_return': 0.0994251208297344,\n",
       "  'std': 0.017765562509066943,\n",
       "  'var': 0.00031561521126356496,\n",
       "  'beta': 0.9911557050728368},\n",
       " 'SAP': {'expected_return': 0.09762442974294032,\n",
       "  'std': 0.018175422266895527,\n",
       "  'var': 0.0003303459745799617,\n",
       "  'beta': 0.9634527652760049},\n",
       " 'TEAM': {'expected_return': 0.09247667789021742,\n",
       "  'std': 0.02861254816737818,\n",
       "  'var': 0.0008186779126305364,\n",
       "  'beta': 0.8842565829264217},\n",
       " 'TXN': {'expected_return': 0.10038761110104466,\n",
       "  'std': 0.018444002465518347,\n",
       "  'var': 0.0003401812269480469,\n",
       "  'beta': 1.0059632477083793},\n",
       " 'WDAY': {'expected_return': 0.11166073354323107,\n",
       "  'std': 0.024632101936279564,\n",
       "  'var': 0.0006067404457992674,\n",
       "  'beta': 1.1793959006650934},\n",
       " 'WORK': {'expected_return': 0.0748700222616795,\n",
       "  'std': 0.04065212267713022,\n",
       "  'var': 0.0016525950781564448,\n",
       "  'beta': 0.6133849578719923},\n",
       " 'XLNX': {'expected_return': 0.10062607706939641,\n",
       "  'std': 0.02065703568493162,\n",
       "  'var': 0.0004267131232885383,\n",
       "  'beta': 1.0096319549137909},\n",
       " 'ZBRA': {'expected_return': 0.10179214662735904,\n",
       "  'std': 0.022044178082334588,\n",
       "  'var': 0.0004859457873256806,\n",
       "  'beta': 1.0275714865747543},\n",
       " 'ZEN': {'expected_return': 0.11520510476757949,\n",
       "  'std': 0.028218080511140713,\n",
       "  'var': 0.0007962600677332192,\n",
       "  'beta': 1.2339246887319921},\n",
       " 'ZI': {'expected_return': 0.09957008353987737,\n",
       "  'std': 0.04599592714933348,\n",
       "  'var': 0.002115625314326793,\n",
       "  'beta': 0.993385900613498},\n",
       " 'ZS': {'expected_return': 0.09180447064267863,\n",
       "  'std': 0.03934516257263749,\n",
       "  'var': 0.001548041817867274,\n",
       "  'beta': 0.8739149329642867}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_calculator(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_expected_return_calculator(stocks, weights):\n",
    "    # Create an empty list which will hold the expected returns\n",
    "    expected_returns = []\n",
    "    # Gather the stock data from the symbol_data_calculator function\n",
    "    symbol_data = stock_data_calculator(stocks)\n",
    "    # Pull only the expected returns from the data\n",
    "    for symbol in symbol_data:\n",
    "        expected_returns.append(symbol_data[symbol]['expected_return'])\n",
    "    # Multiply the expected returns by the weights to get weighted expected returns\n",
    "    weighted_expected_returns = expected_returns * weights\n",
    "    # Sum all these to get the expected return of the portfolio\n",
    "    weighted_expected_returns = weighted_expected_returns.sum()\n",
    "    return weighted_expected_returns \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10524449746872866"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.random(32)\n",
    "weights /= weights.sum()\n",
    "portfolio_expected_return_calculator(stocks, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_variance_calculator(symbols, weights):\n",
    "    # Getting the data. This part can be replaced by anurag's function\n",
    "    df_dict = {}\n",
    "    for symbol in symbols:\n",
    "        symbol_df = pd.read_csv(\n",
    "            Path(f'./Resources/{symbol}.csv'),\n",
    "            index_col = 'Date',\n",
    "            parse_dates = True,\n",
    "            infer_datetime_format = True\n",
    "            )\n",
    "        df_dict[symbol] = symbol_df['Close']\n",
    "\n",
    "    prices_df = pd.concat(df_dict.values(), axis = 1, join = 'inner', keys = stocks)\n",
    "    daily_returns = prices_df.pct_change().dropna()\n",
    "    \n",
    "    # Get the covariance array of the portfolio using the .cov() method.\n",
    "    portfolio_cov = np.array(daily_returns.cov())\n",
    "\n",
    "    # Get the standard deviation of each asset in the portfolio using the .std() method.\n",
    "    portfolio_std = np.array(daily_returns.std())\n",
    "\n",
    "    # Cross multiply the std array with the transposition of itself.\n",
    "    portfolio_stdT = np.transpose(np.array([portfolio_std]))\n",
    "    portfolio_std_cp = portfolio_std * portfolio_stdT\n",
    "\n",
    "    # Get the correlation matrix by dividing the covariance matrix by the standard deviation matrix.\n",
    "    correlation_matrix = portfolio_cov / portfolio_std_cp\n",
    "\n",
    "    # Get weighted standard deviation and save the transposition of that array.\n",
    "    weighted_std = portfolio_std * weights\n",
    "    weighted_stdT = np.transpose(np.array([weighted_std]))\n",
    "\n",
    "    # Calculate portfolio variance by first multiplying the covariance matrix by the \n",
    "    # weighted standard deviation array. This will give an array which is \n",
    "    # 1x<the number of stocks in the portfolio>\n",
    "    portfolio_var = np.matmul(weighted_std, correlation_matrix)\n",
    "    # Then multiplying that array by the transposition of the weighted standard deviation array.\n",
    "    # This will give a single value.\n",
    "    portfolio_var = np.matmul(portfolio_var, weighted_stdT)\n",
    "    # And finally taking the square root of that value.\n",
    "    portfolio_var = np.sqrt(portfolio_var)\n",
    "    return portfolio_var\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01700711])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.random(32)\n",
    "weights /= weights.sum()\n",
    "portfolio_variance_calculator(stocks, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_performance_calculator(stocks, weights):\n",
    "    # This section can be replaced by Anurag's function\n",
    "    df_dict = {}\n",
    "    for stock in stocks:\n",
    "        stock_df = pd.read_csv(\n",
    "            Path(f'./Resources/{stock}.csv'),\n",
    "            index_col = 'Date',\n",
    "            parse_dates = True,\n",
    "            infer_datetime_format = True\n",
    "            )\n",
    "        stock_df['daily_returns'] = stock_df['Close'].pct_change().dropna()\n",
    "        df_dict[stock] = stock_df[['daily_returns']]\n",
    "\n",
    "    stocks_df = pd.concat(df_dict.values(), axis = 1, join = 'inner', keys = stocks)\n",
    "\n",
    "    # Calculate cumulative returns for each stock in the portfolio.\n",
    "    cumulative_returns = (1+stocks_df).cumprod() - 1\n",
    "    # Multiply each stock by its respective weight.\n",
    "    cumulative_returns = cumulative_returns * weights\n",
    "    # Sum all the weighted cumulative returns\n",
    "    cumulative_returns = cumulative_returns.sum(axis=1)\n",
    "    return cumulative_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts a list of stocks and a list of weights which must be in the \n",
    "# same order. It will return the 95% confidence interval for annual performance\n",
    "# of the portfolio.\n",
    "def portfolio_95percent_confidence_calculator(stocks, weights):\n",
    "    expected_return = portfolio_expected_return_calculator(stocks, weights)\n",
    "    variance = portfolio_variance_calculator(stocks, weights)\n",
    "    lower_bound = expected_return - 2*variance\n",
    "    upper_bound = expected_return + 2*variance\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['AAPL',\n",
       "  'ACN',\n",
       "  'ADBE',\n",
       "  'ADI',\n",
       "  'ADSK',\n",
       "  'AKAM',\n",
       "  'AMAT',\n",
       "  'AMD',\n",
       "  'CRM',\n",
       "  'DELL',\n",
       "  'DOCU',\n",
       "  'EPAM',\n",
       "  'FIS',\n",
       "  'FISV',\n",
       "  'IBM',\n",
       "  'INFY',\n",
       "  'LRCX',\n",
       "  'MSFT',\n",
       "  'MU',\n",
       "  'NOW',\n",
       "  'NVDA',\n",
       "  'ORCL',\n",
       "  'SAP',\n",
       "  'TEAM',\n",
       "  'TXN',\n",
       "  'WDAY',\n",
       "  'WORK',\n",
       "  'XLNX',\n",
       "  'ZBRA',\n",
       "  'ZEN',\n",
       "  'ZI',\n",
       "  'ZS'],\n",
       " array([0.00796418, 0.00970689, 0.00430216, 0.03814624, 0.03512294,\n",
       "        0.03962741, 0.04132653, 0.0423957 , 0.02582287, 0.00261783,\n",
       "        0.04008024, 0.05341208, 0.01865945, 0.01817888, 0.05211889,\n",
       "        0.03449983, 0.05917331, 0.01277487, 0.00835608, 0.02860374,\n",
       "        0.02866001, 0.05699303, 0.03078902, 0.01907603, 0.00884182,\n",
       "        0.05689261, 0.04854696, 0.01578096, 0.02045994, 0.05989768,\n",
       "        0.05880154, 0.02237026]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(stocks, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_frontier_generator(stocks):\n",
    "    i = 0\n",
    "    portfolio_dict = {}\n",
    "    while i < 5:\n",
    "        weights = np.random.random(32)\n",
    "        weights /= weights.sum()\n",
    "        portfolio_return = portfolio_expected_return_calculator(stocks, weights)\n",
    "        portfolio_variance = portfolio_variance_calculator(stocks, weights)\n",
    "        portfolio_dict[i] = (portfolio_return, portfolio_variance, weights)\n",
    "        i += 1\n",
    "    return portfolio_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a naive approach to finding the portfolio with the minimum risk.\n",
    "# There is a way to minimize a function with SciPy.optimize.minimize but \n",
    "# I can't figure out how to do it. \n",
    "# This function takes a list of stocks and creates 100 random portfolios\n",
    "# and returns the one with the minimum risk.\n",
    "def naive_minimum_risk_finder(stocks):\n",
    "    # Create an iterator\n",
    "    i = 0\n",
    "    # Create dictionary to store the minimum risk portfolio\n",
    "    min_risk = {}\n",
    "    # Generate 100 portfolios with random weightings.\n",
    "    # Save only the one with the minimim risk.\n",
    "    while i < 100:\n",
    "        weights = np.random.random(len(stocks))\n",
    "        weights /= weights.sum()\n",
    "        risk = portfolio_variance_calculator(stocks, weights)\n",
    "        if not min_risk:\n",
    "            min_risk['min_risk']={'risk':risk, 'weights':weights}\n",
    "        elif risk < min_risk['min_risk']['risk']:\n",
    "            min_risk['min_risk']={'risk':risk, 'weights':weights}\n",
    "        i += 1\n",
    "    return min_risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_risk': {'risk': array([0.01557095]),\n",
       "  'weights': array([0.03555009, 0.04106247, 0.02711876, 0.05355551, 0.05085075,\n",
       "         0.05569532, 0.02766137, 0.00417184, 0.04132095, 0.05444134,\n",
       "         0.02167664, 0.00168093, 0.0427039 , 0.04541502, 0.04944397,\n",
       "         0.04301324, 0.00714041, 0.00122269, 0.05418961, 0.00834471,\n",
       "         0.01915928, 0.01707678, 0.03105469, 0.05607927, 0.02102854,\n",
       "         0.00626393, 0.05665821, 0.03233294, 0.03812038, 0.01266993,\n",
       "         0.01872183, 0.0245747 ])}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_minimum_risk_finder(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a naive approach to finding the portfolio with the minimum risk.\n",
    "# There is a way to minimize a function with SciPy.optimize.minimize but \n",
    "# I can't figure out how to do it. \n",
    "# This function takes a list of stocks and creates 100 random portfolios\n",
    "# and returns the one with the maximum return.\n",
    "def naive_maximum_return_finder(stocks):\n",
    "    i = 0\n",
    "    # Create dictionary to store the maximum return portfolio\n",
    "    max_return = {}\n",
    "    # Generate 100 portfolios with random weightings.\n",
    "    # Save only the one with the minimim risk.\n",
    "    while i < 100:\n",
    "        weights = np.random.random(len(stocks))\n",
    "        weights /= weights.sum()\n",
    "        returns = portfolio_expected_return_calculator(stocks, weights)\n",
    "        if not max_return:\n",
    "            max_return['max_return']={'return':returns, 'weights':weights}\n",
    "        elif returns > max_return['max_return']['return']:\n",
    "            max_return['max_return']={'return':returns, 'weights':weights}\n",
    "        i += 1\n",
    "    return max_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_return': {'return': 0.10868263191557352,\n",
       "  'weights': array([0.01969949, 0.02750897, 0.00905616, 0.00824853, 0.06298531,\n",
       "         0.04530381, 0.00708762, 0.05963186, 0.01863723, 0.0325562 ,\n",
       "         0.00560353, 0.04303172, 0.00824645, 0.01585717, 0.05639183,\n",
       "         0.03405789, 0.03768874, 0.02112605, 0.04026231, 0.0279426 ,\n",
       "         0.05565747, 0.03549286, 0.00933088, 0.02077517, 0.06124776,\n",
       "         0.043136  , 0.02282959, 0.05938845, 0.00284033, 0.05762949,\n",
       "         0.03573454, 0.015014  ])}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_maximum_return_finder(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927-12-30</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1928-01-03</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1928-01-04</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928-01-05</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1928-01-06</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23318</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>3277.169922</td>\n",
       "      <td>3341.050049</td>\n",
       "      <td>3259.820068</td>\n",
       "      <td>3310.110107</td>\n",
       "      <td>3310.110107</td>\n",
       "      <td>4903070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23319</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>3293.590088</td>\n",
       "      <td>3304.929932</td>\n",
       "      <td>3233.939941</td>\n",
       "      <td>3269.959961</td>\n",
       "      <td>3269.959961</td>\n",
       "      <td>4840450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23320</th>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>3296.199951</td>\n",
       "      <td>3330.139893</td>\n",
       "      <td>3279.739990</td>\n",
       "      <td>3310.239990</td>\n",
       "      <td>3310.239990</td>\n",
       "      <td>4310590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23321</th>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>3336.250000</td>\n",
       "      <td>3389.489990</td>\n",
       "      <td>3336.250000</td>\n",
       "      <td>3369.159912</td>\n",
       "      <td>3369.159912</td>\n",
       "      <td>4220070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23322</th>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>3406.459961</td>\n",
       "      <td>3486.250000</td>\n",
       "      <td>3405.169922</td>\n",
       "      <td>3443.439941</td>\n",
       "      <td>3443.439941</td>\n",
       "      <td>4783040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23323 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date         Open         High          Low        Close  \\\n",
       "0      1927-12-30    17.660000    17.660000    17.660000    17.660000   \n",
       "1      1928-01-03    17.760000    17.760000    17.760000    17.760000   \n",
       "2      1928-01-04    17.719999    17.719999    17.719999    17.719999   \n",
       "3      1928-01-05    17.549999    17.549999    17.549999    17.549999   \n",
       "4      1928-01-06    17.660000    17.660000    17.660000    17.660000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "23318  2020-10-29  3277.169922  3341.050049  3259.820068  3310.110107   \n",
       "23319  2020-10-30  3293.590088  3304.929932  3233.939941  3269.959961   \n",
       "23320  2020-11-02  3296.199951  3330.139893  3279.739990  3310.239990   \n",
       "23321  2020-11-03  3336.250000  3389.489990  3336.250000  3369.159912   \n",
       "23322  2020-11-04  3406.459961  3486.250000  3405.169922  3443.439941   \n",
       "\n",
       "         Adj Close      Volume  \n",
       "0        17.660000           0  \n",
       "1        17.760000           0  \n",
       "2        17.719999           0  \n",
       "3        17.549999           0  \n",
       "4        17.660000           0  \n",
       "...            ...         ...  \n",
       "23318  3310.110107  4903070000  \n",
       "23319  3269.959961  4840450000  \n",
       "23320  3310.239990  4310590000  \n",
       "23321  3369.159912  4220070000  \n",
       "23322  3443.439941  4783040000  \n",
       "\n",
       "[23323 rows x 7 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_data.get_historical_data('SPX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d97317d8a5f3767d631f8f5f9cb1ef3203497d7b6331512fb7f06b031b983eac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
